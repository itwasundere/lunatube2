// Generated by CoffeeScript 1.4.0
(function() {
  var cache, cache_file, classname, dump, file, load, models, read, schema, schema_file, schemas, spark, write, yaml, yparse;

  file = require('fs');

  yaml = require('js-yaml');

  spark = require('./spark');

  yparse = yaml.load;

  read = file.readFileSync;

  write = file.writeFileSync;

  cache_file = process.cwd() + '/data/data.json';

  schema_file = process.cwd() + '/res/schema.yaml';

  cache = spark.cache;

  load = function() {
    var count, dumpfile, i, id, obj;
    dumpfile = JSON.parse(read(cache_file, 'utf8'));
    for (id in dumpfile) {
      obj = dumpfile[id];
      if (!obj.type || !models[obj.type]) {
        continue;
      }
      cache[id] = new models[obj.type];
      cache[id].load(obj);
    }
    count = 0;
    for (i in cache) {
      count++;
    }
    return console.log(count + ' objects loaded to cache');
  };

  dump = function() {
    var count, dumpfile, i, id, obj;
    dumpfile = {};
    for (id in cache) {
      obj = cache[id];
      if (obj.throwaway) {
        continue;
      }
      dumpfile[id] = obj.json();
    }
    write(cache_file, JSON.stringify(dumpfile));
    count = 0;
    for (i in cache) {
      count++;
    }
    return console.log(count + ' objects loaded to file');
  };

  models = {};

  schemas = yparse(read(schema_file, 'utf8'));

  for (classname in schemas) {
    schema = schemas[classname];
    models[classname] = spark.genclass(classname, schema.attrs, schema.links);
    models[classname + 'list'] = spark.gencol(classname, models[classname]);
  }

  module.exports = {
    models: models,
    cache: spark.cache,
    lookup: spark.lookup,
    dump: dump,
    load: load
  };

}).call(this);
